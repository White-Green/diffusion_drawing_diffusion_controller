{
  "1": {
    "inputs": {
      "ckpt_name": "animagineXLV31_v31.safetensors"
    },
    "class_type": "CheckpointLoaderSimple"
  },
  "3": {
    "inputs": {
      "text": "${PROMPT} sharp lines, masterpiece, best quality, very aesthetic, absurdres",
      "clip": [
        "86",
        1
      ]
    },
    "class_type": "CLIPTextEncode"
  },
  "7": {
    "inputs": {
      "text": "monochrome, sketch, blurred, soft edge, bokeh, wrong, ugly, bad feet, bad hands, bad art, ugly artstyle, bad anatomy, bad fingers, censor, censored, ugly, deformed, noisy, blurry, low contrast, photo, realistic ,watermark, username, text",
      "clip": [
        "86",
        1
      ]
    },
    "class_type": "CLIPTextEncode"
  },
  "9": {
    "inputs": {
      "samples": [
        "69",
        0
      ],
      "vae": [
        "11",
        0
      ]
    },
    "class_type": "VAEDecode"
  },
  "11": {
    "inputs": {
      "vae_name": "Animagine_xl_3_1_vae.safetensors"
    },
    "class_type": "VAELoader"
  },
  "12": {
    "inputs": {
      "control_net_name": "controlnet852A_normal.safetensors"
    },
    "class_type": "ControlNetLoader"
  },
  "13": {
    "inputs": {
      "strength": 1,
      "start_percent": 0,
      "end_percent": 0.8,
      "positive": [
        "3",
        0
      ],
      "negative": [
        "7",
        0
      ],
      "control_net": [
        "59",
        0
      ],
      "image": [
        "62",
        0
      ],
      "vae": [
        "11",
        0
      ]
    },
    "class_type": "ControlNetApplyAdvanced"
  },
  "14": {
    "inputs": {
      "image": "diffusion_drawing_temporary_scribble.png",
      "upload": "image"
    },
    "class_type": "LoadImage"
  },
  "15": {
    "inputs": {
      "coarse": "disable",
      "resolution": 512,
      "image": [
        "14",
        0
      ]
    },
    "class_type": "LineArtPreprocessor"
  },
  "17": {
    "inputs": {
      "resolution": 1024,
      "image": [
        "9",
        0
      ]
    },
    "class_type": "AnimeLineArtPreprocessor"
  },
  "19": {
    "inputs": {
      "image": [
        "17",
        0
      ]
    },
    "class_type": "ImageInvert"
  },
  "37": {
    "inputs": {
      "seed": 188939767741490,
      "steps": 20,
      "cfg": 8,
      "sampler_name": "euler",
      "scheduler": "normal",
      "denoise": 1,
      "model": [
        "86",
        0
      ],
      "positive": [
        "13",
        0
      ],
      "negative": [
        "13",
        1
      ],
      "latent_image": [
        "44",
        0
      ]
    },
    "class_type": "KSampler"
  },
  "42": {
    "inputs": {
      "image": "diffusion_drawing_temporary_lineart.png",
      "upload": "image"
    },
    "class_type": "LoadImage"
  },
  "44": {
    "inputs": {
      "grow_mask_by": 0,
      "pixels": [
        "42",
        0
      ],
      "vae": [
        "11",
        0
      ],
      "mask": [
        "42",
        1
      ]
    },
    "class_type": "VAEEncodeForInpaint"
  },
  "47": {
    "inputs": {
      "mask": [
        "42",
        1
      ]
    },
    "class_type": "MaskToImage"
  },
  "48": {
    "inputs": {},
    "class_type": "PreviewImage"
  },
  "50": {
    "inputs": {},
    "class_type": "PreviewImage"
  },
  "51": {
    "inputs": {},
    "class_type": "PreviewImage"
  },
  "53": {
    "inputs": {
      "mask": [
        "42",
        1
      ]
    },
    "class_type": "InvertMask"
  },
  "54": {
    "inputs": {
      "mask": [
        "53",
        0
      ]
    },
    "class_type": "MaskToImage"
  },
  "55": {
    "inputs": {},
    "class_type": "PreviewImage"
  },
  "57": {
    "inputs": {
      "image": [
        "14",
        0
      ]
    },
    "class_type": "ImageInvert"
  },
  "59": {
    "inputs": {
      "control_net_name": "mistoline_v10.safetensors",
      "model": [
        "86",
        0
      ]
    },
    "class_type": "DiffControlNetLoader"
  },
  "62": {
    "inputs": {
      "image_in": [
        "14",
        0
      ]
    },
    "class_type": "DiffusionDrawingScribblePreprocess"
  },
  "67": {
    "inputs": {
      "control_net_name": "controlnet852A_normal.safetensors",
      "model": [
        "86",
        0
      ]
    },
    "class_type": "DiffControlNetLoader"
  },
  "69": {
    "inputs": {
      "seed": "${RANDOM_SEED}",
      "steps": 20,
      "cfg": 8,
      "sampler_name": "euler",
      "scheduler": "normal",
      "denoise": 0.4,
      "model": [
        "86",
        0
      ],
      "positive": [
        "3",
        0
      ],
      "negative": [
        "7",
        0
      ],
      "latent_image": [
        "37",
        0
      ]
    },
    "class_type": "KSampler"
  },
  "70": {
    "inputs": {
      "samples": [
        "37",
        0
      ],
      "vae": [
        "11",
        0
      ]
    },
    "class_type": "VAEDecode"
  },
  "71": {
    "inputs": {},
    "class_type": "PreviewImage"
  },
  "72": {
    "inputs": {
      "coarse": "disable",
      "resolution": 1024
    },
    "class_type": "LineArtPreprocessor"
  },
  "73": {
    "inputs": {
      "guassian_sigma": 2,
      "intensity_threshold": 8,
      "resolution": 1024
    },
    "class_type": "LineartStandardPreprocessor"
  },
  "74": {
    "inputs": {
      "merge_with_lineart": "lineart_standard",
      "resolution": 1024,
      "lineart_lower_bound": 0,
      "lineart_upper_bound": 1,
      "object_min_size": 36,
      "object_connectivity": 1
    },
    "class_type": "AnyLineArtPreprocessor_aux"
  },
  "75": {
    "inputs": {
      "resolution": 1024
    },
    "class_type": "Manga2Anime_LineArt_Preprocessor"
  },
  "76": {
    "inputs": {
      "image": [
        "72",
        0
      ]
    },
    "class_type": "ImageInvert"
  },
  "77": {
    "inputs": {
      "image": [
        "73",
        0
      ]
    },
    "class_type": "ImageInvert"
  },
  "78": {
    "inputs": {
      "image": [
        "74",
        0
      ]
    },
    "class_type": "ImageInvert"
  },
  "79": {
    "inputs": {
      "image": [
        "75",
        0
      ]
    },
    "class_type": "ImageInvert"
  },
  "86": {
    "inputs": {
      "lora_name": "pytorch_lora_weights.bin",
      "strength_model": 1,
      "strength_clip": 1,
      "model": [
        "1",
        0
      ],
      "clip": [
        "1",
        1
      ]
    },
    "class_type": "LoraLoader"
  },
  "88": {
    "inputs": {
      "image_in": [
        "19",
        0
      ]
    },
    "class_type": "DiffusionDrawingLineart2Transparency"
  },
  "89": {
    "inputs": {
      "images": [
        "88",
        0
      ]
    },
    "class_type": "PreviewImage"
  }
}
